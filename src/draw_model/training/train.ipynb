{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T01:47:45.977966Z",
     "iopub.status.busy": "2025-10-19T01:47:45.977698Z",
     "iopub.status.idle": "2025-10-19T01:48:00.113140Z",
     "shell.execute_reply": "2025-10-19T01:48:00.112400Z",
     "shell.execute_reply.started": "2025-10-19T01:47:45.977943Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/apple.npy...\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/banana.npy...                  \n",
      "==> NOTE: You are downloading one or more large file(s), which would            \n",
      "run significantly faster if you enabled sliced object downloads. This\n",
      "feature is enabled by default but requires that compiled crcmod be\n",
      "installed (see \"gsutil help crcmod\").\n",
      "\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/book.npy...\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/cake.npy...                    \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/car.npy...                     \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/cloud.npy...                   \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/cup.npy...                     \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/door.npy...                    \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/envelope.npy...                \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy...              \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/finger.npy...                  \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/fish.npy...                    \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/flower.npy...                  \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/fork.npy...                    \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/grass.npy...                   \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/guitar.npy...                  \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/hamburger.npy...               \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/headphones.npy...              \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/house.npy...                   \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/ice cream.npy...               \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/knife.npy...                   \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/leaf.npy...\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/pants.npy...\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/pencil.npy...\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/pizza.npy...\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/spoon.npy...                   \n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/star.npy...\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/sword.npy...\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/t-shirt.npy...\n",
      "Copying gs://quickdraw_dataset/full/numpy_bitmap/umbrella.npy...                \n",
      "\\ [30/30 files][  3.1 GiB/  3.1 GiB] 100% Done 248.8 MiB/s ETA 00:00:00         \n",
      "Operation completed over 30 objects/3.1 GiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/apple.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/banana.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/book.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/cake.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/car.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/cloud.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/cup.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/door.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/envelope.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/finger.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/fish.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/flower.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/fork.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/grass.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/guitar.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/hamburger.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/headphones.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/house.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/ice cream.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/knife.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/leaf.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/pants.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/pencil.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/pizza.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/spoon.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/star.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/sword.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\" \\\n",
    "  \"gs://quickdraw_dataset/full/numpy_bitmap/umbrella.npy\" ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrYWbchaA-Wt"
   },
   "source": [
    "Download all the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHa9QkuzA86n"
   },
   "source": [
    "Import all library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T01:48:07.862347Z",
     "iopub.status.busy": "2025-10-19T01:48:07.861532Z",
     "iopub.status.idle": "2025-10-19T01:48:13.363475Z",
     "shell.execute_reply": "2025-10-19T01:48:13.362893Z",
     "shell.execute_reply.started": "2025-10-19T01:48:07.862313Z"
    },
    "id": "a82bc8ed",
    "outputId": "23f26d42-4f65-42fd-8770-7c1ec2f06730",
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjgGWSnJCiJr"
   },
   "source": [
    "Basic constant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T01:50:48.098708Z",
     "iopub.status.busy": "2025-10-19T01:50:48.098408Z",
     "iopub.status.idle": "2025-10-19T01:50:48.161602Z",
     "shell.execute_reply": "2025-10-19T01:50:48.160947Z",
     "shell.execute_reply.started": "2025-10-19T01:50:48.098681Z"
    },
    "id": "HJMT8UkZBOjk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DIR_FILE = os.path.join(BASE_DIR, 'data')\n",
    "FILE_NAME = [os.path.join(DIR_FILE, f) for f in os.listdir(DIR_FILE)]\n",
    "NUM_CLASSES = len(FILE_NAME)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "CLASS_NAMES = [os.path.splitext(f)[0] for f in os.listdir(DIR_FILE)]\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "CHECKPOINT_PATH = os.path.join(BASE_DIR, 'model.pt')\n",
    "\n",
    "THRESHOLD_PROB = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cztIPFXtCw5u"
   },
   "source": [
    "Basic config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T01:50:50.095071Z",
     "iopub.status.busy": "2025-10-19T01:50:50.094370Z",
     "iopub.status.idle": "2025-10-19T01:50:50.105100Z",
     "shell.execute_reply": "2025-10-19T01:50:50.104539Z",
     "shell.execute_reply.started": "2025-10-19T01:50:50.095047Z"
    },
    "id": "4jv1DsC1BGRI",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class QuickDrawDataset(Dataset):\n",
    "    def __init__(self, file_names):\n",
    "        self.file_names = file_names\n",
    "        self.data_list = [np.load(f, mmap_mode='r') for f in file_names]\n",
    "        self.labels = list(range(len(file_names)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(d) for d in self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        total = 0\n",
    "        for i, data in enumerate(self.data_list):\n",
    "            if idx < total + len(data):\n",
    "                item = data[idx - total].reshape(28, 28)\n",
    "                item = torch.tensor(item, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "                return item, self.labels[i]\n",
    "            total += len(data)\n",
    "\n",
    "dataset = QuickDrawDataset(FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzYk4mPQDVRW"
   },
   "source": [
    "Basic load and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T01:50:59.452214Z",
     "iopub.status.busy": "2025-10-19T01:50:59.451912Z",
     "iopub.status.idle": "2025-10-19T01:50:59.458245Z",
     "shell.execute_reply": "2025-10-19T01:50:59.457356Z",
     "shell.execute_reply.started": "2025-10-19T01:50:59.452192Z"
    },
    "id": "Y2D1YG6MDHw2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_model(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Adam,\n",
    "    file_name: str,\n",
    ") -> tuple[int, int]:\n",
    "    checkpoint = torch.load(file_name)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return loss, epoch\n",
    "\n",
    "def save_model(\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Adam,\n",
    "    epoch: int,\n",
    "    file_name: str,\n",
    "    loss: float\n",
    ") -> None:\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot5fGUjhC68f"
   },
   "source": [
    "Model draw_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T01:51:02.106726Z",
     "iopub.status.busy": "2025-10-19T01:51:02.105964Z",
     "iopub.status.idle": "2025-10-19T01:51:02.120949Z",
     "shell.execute_reply": "2025-10-19T01:51:02.120194Z",
     "shell.execute_reply.started": "2025-10-19T01:51:02.106692Z"
    },
    "id": "QlbJYYkPC4Ee",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DrawModel(nn.Module):\n",
    "    def __init__(self, num_classes = 3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool2 = nn.Sequential(\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.flat = nn.Flatten() #256 gia tri 4 * 4 * 16\n",
    "        self.fc_1 = nn.Sequential(\n",
    "            nn.Linear(in_features=16 * 4 * 4, out_features=120, device=DEVICE),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_2 = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84, device=DEVICE),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Linear(in_features=84, out_features=num_classes, device=DEVICE)\n",
    "    def forward(self, input):\n",
    "        input = self.conv1(input)\n",
    "        input = self.pool1(input)\n",
    "        input = self.conv2(input)\n",
    "        input = self.pool2(input)\n",
    "        input = self.flat(input)\n",
    "        input = self.fc_1(input)\n",
    "        input = self.fc_2(input)\n",
    "        return self.out(input)\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        dataset: Dataset,\n",
    "        loss: float,\n",
    "        optimizer: torch.optim.Adam,\n",
    "        criterion: nn.CrossEntropyLoss = nn.CrossEntropyLoss(),\n",
    "        start_epoch: int = 1\n",
    "    ) -> None:\n",
    "        if start_epoch > NUM_EPOCHS:\n",
    "            print(f'Training complete with full epoch')\n",
    "            return\n",
    "\n",
    "        train_size = int(TRAIN_SPLIT * len(dataset))\n",
    "        valid_size = len(dataset) - int(TRAIN_SPLIT * len(dataset))\n",
    "        train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "        best_model = copy.deepcopy(self.state_dict())\n",
    "        best_valid_loss = loss\n",
    "\n",
    "        for epoch in range(start_epoch, NUM_EPOCHS + 1):\n",
    "            self.train()\n",
    "            print(f'Running with epoch: {epoch} / {NUM_EPOCHS}')\n",
    "            epoch_train_loss = 0\n",
    "            total_loop_train = 0\n",
    "            acc_score = 0\n",
    "\n",
    "            #Train loop\n",
    "            for batch in train_loader:\n",
    "                x_batch, y_batch = batch\n",
    "                x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "                # train step\n",
    "                logits = self(x_batch)\n",
    "\n",
    "                #Calculate loss with prediction and true label with CrossEntropyLoss\n",
    "                loss: torch.Tensor = criterion(logits, y_batch)\n",
    "\n",
    "                # Backpropagation\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Sum of total loss in one epoch\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "                #Get the highest probability of each class\n",
    "                pred = logits.argmax(dim = 1)\n",
    "                F.softmax\n",
    "                #Calculate the accuracy of prediction\n",
    "                acc_score += accuracy_score(y_batch.cpu(), pred.cpu())\n",
    "                total_loop_train += 1\n",
    "\n",
    "            #Valid\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                total_loop_valid = 0\n",
    "                valid_score = 0\n",
    "                epoch_valid_loss = 0\n",
    "                for batch in valid_loader:\n",
    "                    x_batch, y_batch = batch\n",
    "                    x_batch, y_batch = x_batch.to(DEVICE), y_batch.to(DEVICE)\n",
    "                    logits = self(x_batch)\n",
    "                    loss: torch.Tensor = criterion(logits, y_batch)\n",
    "                    epoch_valid_loss += loss.item()\n",
    "                    pred = logits.argmax(dim = 1)\n",
    "                    valid_score += accuracy_score(y_batch.cpu(), pred.cpu())\n",
    "                    total_loop_valid += 1\n",
    "\n",
    "            acc_train_score = acc_score / total_loop_train\n",
    "            acc_valid_score = valid_score / total_loop_valid\n",
    "            loss_train = epoch_train_loss / len(train_loader)\n",
    "            loss_valid = epoch_valid_loss / len(valid_loader)\n",
    "            print(f'Training loss: {loss_train:.4f}. Training accuracy: {acc_train_score:.4f}')\n",
    "            print(f'Validation loss: {loss_valid:.4f}. Validation accuracy: {acc_valid_score:.4f}')\n",
    "            if loss_valid < best_valid_loss:\n",
    "                best_valid_loss = loss_valid\n",
    "                best_model = copy.deepcopy(self.state_dict())\n",
    "                save_model(model=self, loss=best_valid_loss, optimizer=optimizer, epoch=epoch, file_name=CHECKPOINT_PATH)\n",
    "                print(f'Best validation loss: {best_valid_loss:.4f}')\n",
    "            self.load_state_dict(best_model)\n",
    "            print(f'Model saved to {CHECKPOINT_PATH} successfully')\n",
    "\n",
    "    def load(\n",
    "        self,\n",
    "        file_name: str\n",
    "    ) -> nn.Module:\n",
    "        checkpoint = torch.load(file_name)\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.eval()\n",
    "        return self\n",
    "\n",
    "    def predict(self, input):\n",
    "        self.load(CHECKPOINT_PATH).to(DEVICE)\n",
    "        input = input.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            logits = self(input)\n",
    "            preds = F.softmax(logits, dim=1)\n",
    "            values, indices = preds.max(dim=1)\n",
    "            return [CLASS_NAMES[idx.item()] if value.item() >= THRESHOLD_PROB else \"UNKNOWN\" for value, idx in zip(values, indices)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2H64SxcDjok"
   },
   "source": [
    "Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-19T01:51:06.217250Z",
     "iopub.status.busy": "2025-10-19T01:51:06.216643Z",
     "iopub.status.idle": "2025-10-19T03:26:38.279529Z",
     "shell.execute_reply": "2025-10-19T03:26:38.278814Z",
     "shell.execute_reply.started": "2025-10-19T01:51:06.217227Z"
    },
    "id": "rPnAkgpgDYs3",
    "outputId": "67396402-4e26-4cb0-fc64-6a579a1fa306",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with epoch: 1 / 20\n",
      "Training loss: 0.5056. Training accuracy: 0.8630\n",
      "Validation loss: 0.3661. Validation accuracy: 0.9013\n",
      "Best validation loss: 0.3661\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 2 / 20\n",
      "Training loss: 0.3433. Training accuracy: 0.9074\n",
      "Validation loss: 0.3319. Validation accuracy: 0.9094\n",
      "Best validation loss: 0.3319\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 3 / 20\n",
      "Training loss: 0.3211. Training accuracy: 0.9134\n",
      "Validation loss: 0.3150. Validation accuracy: 0.9152\n",
      "Best validation loss: 0.3150\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 4 / 20\n",
      "Training loss: 0.3112. Training accuracy: 0.9159\n",
      "Validation loss: 0.3084. Validation accuracy: 0.9164\n",
      "Best validation loss: 0.3084\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 5 / 20\n",
      "Training loss: 0.3055. Training accuracy: 0.9174\n",
      "Validation loss: 0.2987. Validation accuracy: 0.9194\n",
      "Best validation loss: 0.2987\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 6 / 20\n",
      "Training loss: 0.3015. Training accuracy: 0.9183\n",
      "Validation loss: 0.3002. Validation accuracy: 0.9193\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 7 / 20\n",
      "Training loss: 0.3013. Training accuracy: 0.9183\n",
      "Validation loss: 0.2969. Validation accuracy: 0.9198\n",
      "Best validation loss: 0.2969\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 8 / 20\n",
      "Training loss: 0.2986. Training accuracy: 0.9192\n",
      "Validation loss: 0.2981. Validation accuracy: 0.9192\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 9 / 20\n",
      "Training loss: 0.2984. Training accuracy: 0.9193\n",
      "Validation loss: 0.2999. Validation accuracy: 0.9195\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 10 / 20\n",
      "Training loss: 0.2985. Training accuracy: 0.9192\n",
      "Validation loss: 0.2932. Validation accuracy: 0.9210\n",
      "Best validation loss: 0.2932\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 11 / 20\n",
      "Training loss: 0.2961. Training accuracy: 0.9198\n",
      "Validation loss: 0.2980. Validation accuracy: 0.9196\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 12 / 20\n",
      "Training loss: 0.2961. Training accuracy: 0.9198\n",
      "Validation loss: 0.2997. Validation accuracy: 0.9195\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 13 / 20\n",
      "Training loss: 0.2958. Training accuracy: 0.9199\n",
      "Validation loss: 0.2970. Validation accuracy: 0.9196\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 14 / 20\n",
      "Training loss: 0.2960. Training accuracy: 0.9199\n",
      "Validation loss: 0.2967. Validation accuracy: 0.9205\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 15 / 20\n",
      "Training loss: 0.2961. Training accuracy: 0.9198\n",
      "Validation loss: 0.2935. Validation accuracy: 0.9210\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 16 / 20\n",
      "Training loss: 0.2962. Training accuracy: 0.9197\n",
      "Validation loss: 0.2937. Validation accuracy: 0.9209\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 17 / 20\n",
      "Training loss: 0.2961. Training accuracy: 0.9198\n",
      "Validation loss: 0.2994. Validation accuracy: 0.9194\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 18 / 20\n",
      "Training loss: 0.2962. Training accuracy: 0.9198\n",
      "Validation loss: 0.2989. Validation accuracy: 0.9195\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 19 / 20\n",
      "Training loss: 0.2963. Training accuracy: 0.9198\n",
      "Validation loss: 0.2999. Validation accuracy: 0.9191\n",
      "Model saved to /kaggle/working/model.pt successfully\n",
      "Running with epoch: 20 / 20\n",
      "Training loss: 0.2961. Training accuracy: 0.9198\n",
      "Validation loss: 0.2951. Validation accuracy: 0.9203\n",
      "Model saved to /kaggle/working/model.pt successfully\n"
     ]
    }
   ],
   "source": [
    "model = DrawModel(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start_epoch = 1\n",
    "loss = 1\n",
    "try:\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        loss, start_epoch = load_model(model, optimizer, CHECKPOINT_PATH) + 1\n",
    "        print(f'Resume training from epoch {start_epoch}')\n",
    "except Exception as e:\n",
    "    print(f'Error loading model: {e}')\n",
    "\n",
    "model.fit(dataset, loss, optimizer=optimizer, criterion=criterion, start_epoch=start_epoch)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
